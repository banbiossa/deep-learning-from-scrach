{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.5_ss_chap5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src import utils\n",
    "import itertools\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_fmt = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "logging.basicConfig(level=logging.INFO, format=log_fmt)\n",
    "# logging.basicConfig(level=logging.DEBUG, format=log_fmt)\n",
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulLayer:\n",
    "        def __init__(self):\n",
    "                ''' Multiplication interface for backward propagation\n",
    "                Multiplication returns f(x,y) =x * y\n",
    "                The chain rule stands: df/dx = y, df/dy = x \n",
    "                Backward propagation is: dx = dout * df/dx = dout * y\n",
    "                Backward propagation is: dy = dout * df/dy = dout * x\n",
    "                \n",
    "                Properties\n",
    "                x: num\n",
    "                        Forward x\n",
    "                y: num\n",
    "                        Forward y\n",
    "                '''\n",
    "                self.x = None\n",
    "                self.y = None\n",
    "        \n",
    "        def forward(self, x, y):\n",
    "                ''' Forward method of multiplication\n",
    "                Initalized x, y on forward\n",
    "                '''\n",
    "                self.x = x\n",
    "                self.y = y\n",
    "                out = x * y\n",
    "                \n",
    "                return out\n",
    "        \n",
    "        def backward(self, dout):\n",
    "                ''' Backward method of multiplication\n",
    "                Chain rule follows that df/dx=y, df/dx=x\n",
    "                '''\n",
    "                dx = dout * self.y\n",
    "                dy = dout * self.x\n",
    "                \n",
    "                return dx, dy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = 100\n",
    "apple_num = 2\n",
    "tax = 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer\n",
    "mul_apple_layer = MulLayer()\n",
    "mul_tax_layer = MulLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward\n",
    "apple_price = mul_apple_layer.forward(apple, apple_num)\n",
    "price = mul_tax_layer.forward(apple_price, tax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220.00000000000003\n"
     ]
    }
   ],
   "source": [
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward\n",
    "dprice = 1\n",
    "dapple_price, dtax = mul_tax_layer.backward(dprice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2\n"
     ]
    }
   ],
   "source": [
    "print(dapple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.00000000000001\n"
     ]
    }
   ],
   "source": [
    "print(dapple_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayer:\n",
    "        ''' add interface for backward propagation\n",
    "        add returns f(x,y) =x + y\n",
    "        The chain rule stands: df/dx = 1, df/dy = 1 \n",
    "        Backward propagation is: dx = dout * df/dx = dout * 1\n",
    "        Backward propagation is: dy = dout * df/dy = dout * 1\n",
    "\n",
    "        Properties\n",
    "        x: num\n",
    "                Forward x\n",
    "        y: num\n",
    "                Forward y\n",
    "        '''\n",
    "        def __init__(self):\n",
    "                pass\n",
    "        \n",
    "        def forward(self, x, y):\n",
    "                out = x + y\n",
    "                return out\n",
    "        \n",
    "        def backward(self, dout):\n",
    "                dx = dout * 1\n",
    "                dy = dout * 1\n",
    "                return dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "orange = 150\n",
    "orange_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul_orange_layer = MulLayer()\n",
    "add_apple_orange_layer = AddLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "orange_price = mul_orange_layer.forward(orange, orange_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_price = add_apple_orange_layer.forward(apple_price, orange_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = mul_tax_layer.forward(all_price, tax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprice = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dall_price, dtax = mul_tax_layer.backward(dprice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dapple_price, dorange_price = add_apple_orange_layer.backward(dall_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dorange, dorange_num = mul_orange_layer.backward(dorange_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dapple, dapple_num = mul_apple_layer.backward(dapple_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715.0000000000001\n"
     ]
    }
   ],
   "source": [
    "print(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110.00000000000001"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dapple_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dorange_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relu:\n",
    "        ''' Relu activation\n",
    "        f(x) = x (x > 0), 0 (x <=0)\n",
    "        df/dx = 1(x>0), 0(x<=0)\n",
    "        '''\n",
    "        def __init__(self):\n",
    "                self.mask = None\n",
    "        \n",
    "        def forward(self, x):\n",
    "                ''' output relu\n",
    "                \n",
    "                Parameters\n",
    "                ----------\n",
    "                x: numpy array\n",
    "                \n",
    "                Returns\n",
    "                -------\n",
    "                out: numpy array\n",
    "                        masked as 0 where x<=0\n",
    "                '''\n",
    "                self.mask = (x <= 0)\n",
    "                out = x.copy()\n",
    "                out[self.mask] = 0\n",
    "                \n",
    "                return out\n",
    "        \n",
    "        def backward(self, dout):\n",
    "                dout[self.mask] = 0\n",
    "                dx = dout\n",
    "                \n",
    "                return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "        ''' Sigmoid interface\n",
    "        y = f(x) = 1/(1+exp(-x))\n",
    "        dy/dx = exp(-x)/(1+exp(-x))^2 = y(1-y)\n",
    "        '''\n",
    "        def __init__(self):\n",
    "                self.out = None\n",
    "        \n",
    "        def forward(self, x):\n",
    "                out = 1/(1+np.exp(-x))\n",
    "                self.out = out\n",
    "                \n",
    "                return out\n",
    "        \n",
    "        def backward(self, dout):\n",
    "                dx = dout * (1.0 - self.out) * self.out\n",
    "                \n",
    "                return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "        ''' Interface for affine transformation (dot product)\n",
    "        f(x, W, b) = x %*% W + b\n",
    "        df/dx = W.T\n",
    "        df/dW = x.T\n",
    "        df/db = 1\n",
    "        \n",
    "        '''\n",
    "        def __init__(self, W, b):\n",
    "                self.W = W\n",
    "                self.x = None\n",
    "                self.dW = None\n",
    "                self.db = None\n",
    "        \n",
    "        def forward(self, x):\n",
    "                self.x = x\n",
    "                out = np.dot(x, self.W) + self.b\n",
    "                \n",
    "                return out\n",
    "        \n",
    "        def backward(self, dout):\n",
    "                dx = np.dot(dout, self.W.T)\n",
    "                self.dW = np.dot(self.x.T, dout)\n",
    "                self.db = np.sum(dout, axis=0)\n",
    "                \n",
    "                return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common.functions import softmax, cross_entropy_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "        def __init__(self):\n",
    "                self.loss = None\n",
    "                self.y = None\n",
    "                self.t = None\n",
    "        \n",
    "        def forward(self, x, t):\n",
    "                self.t = t\n",
    "                self.y = softmax(x)\n",
    "                self.loss = cross_entropy_error(self.y, self.t)\n",
    "                \n",
    "                return self.loss\n",
    "        \n",
    "        def backward(self, dout=1):\n",
    "                batch_size = self.t.shape[0]\n",
    "                dx = (self.y - self.t)/batch_size\n",
    "                \n",
    "                return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common.layers import *\n",
    "from src.common.gradient import numerical_gradient\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "        ''' Two layered net\n",
    "        '''\n",
    "        def __init__(self, input_size, hidden_size, output_size,\n",
    "                    weight_init_std = 0.01):\n",
    "                # Initialize\n",
    "                self.params={}\n",
    "                self.params['W1'] = weight_init_std * \\\n",
    "                        np.random.randn(input_size, hidden_size)\n",
    "                self.params['b1'] = np.zeros(hidden_size)\n",
    "                self.params['W2'] = weight_init_std * \\\n",
    "                        np.random.randn(hidden_size, output_size)\n",
    "                self.params['b2'] = np.zeros(output_size)\n",
    "                \n",
    "                # Layers\n",
    "                self.layers = OrderedDict()\n",
    "                self.layers['Affine1'] = Affine(self.params['W1'],\n",
    "                                               self.params['b1'])\n",
    "                self.layers['Relu1'] = Relu()\n",
    "                self.layers['Affine2'] = Affine(self.params['W2'],\n",
    "                                               self.params['b2'])\n",
    "                \n",
    "                self.lastLayer = SoftmaxWithLoss()\n",
    "\n",
    "        def predict(self, x):\n",
    "                for layer in self.layers.values():\n",
    "                        x = layer.forward(x)\n",
    "                \n",
    "                return x\n",
    "        \n",
    "        # x: in, t: out\n",
    "        def loss(self, x, t):\n",
    "                y = self.predict(x)\n",
    "                return self.lastLayer.forward(y, t)\n",
    "        \n",
    "        def accuracy(self, x, t):\n",
    "                y = self.predict(x)\n",
    "                y = np.argmax(y, axis=1)\n",
    "                if t.ndim != 1: \n",
    "                        t = np.argmax(t, axis=1)\n",
    "                accuracy = np.sum(y==t)/float(x.shape[0])\n",
    "                \n",
    "                return accuracy\n",
    "        \n",
    "        def numerical_gradient(self, x, t):\n",
    "                loss_W = lambda W: self.loss(x, t)\n",
    "                \n",
    "                grads = {}\n",
    "                grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "                grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "                grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "                grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "                \n",
    "                return grads\n",
    "        \n",
    "        def gradient(self, x, t):\n",
    "                # forward\n",
    "                self.loss(x, t)\n",
    "                \n",
    "                # backward\n",
    "                dout = 1\n",
    "                dout = self.lastLayer.backward(dout)\n",
    "                \n",
    "                layers = list(self.layers.values())\n",
    "                layers.reverse()\n",
    "                for layer in layers:\n",
    "                        dout = layer.backward(dout)\n",
    "                        \n",
    "                # input\n",
    "                grads = {}\n",
    "                grads['W1'] = self.layers['Affine1'].dW\n",
    "                grads['b1'] = self.layers['Affine1'].db\n",
    "                grads['W2'] = self.layers['Affine2'].dW\n",
    "                grads['b2'] = self.layers['Affine2'].db\n",
    "                \n",
    "                return grads\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dataset.mnist import load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, \n",
    "                                                  one_hot_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = x_train[:3]\n",
    "t_batch = t_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_numerical = network.numerical_gradient(x_batch, t_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_backprop = network.gradient(x_batch, t_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-04 18:53:19,609 - src.common.layers - INFO - W1: 4.246875568409945e-10\n",
      "2018-11-04 18:53:19,610 - src.common.layers - INFO - b1: 2.4277005349551273e-09\n",
      "2018-11-04 18:53:19,613 - src.common.layers - INFO - W2: 5.425777944473201e-09\n",
      "2018-11-04 18:53:19,617 - src.common.layers - INFO - b2: 1.3944884606070795e-07\n"
     ]
    }
   ],
   "source": [
    "for key in grad_numerical.keys():\n",
    "        diff = np.average(np.abs(grad_backprop[key] - grad_numerical[key]))\n",
    "        logger.info(f\"{key}: {diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, \n",
    "                                                  one_hot_label=True)\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "iters_num = 10000\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size/batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-11-04 22:11:17,714 - src.common.layers - INFO - Train: 0.98975, test: 0.9729\n",
      "2018-11-04 22:11:19,511 - src.common.layers - INFO - Train: 0.9908, test: 0.9742\n",
      "2018-11-04 22:11:20,974 - src.common.layers - INFO - Train: 0.9918333333333333, test: 0.9739\n",
      "2018-11-04 22:11:22,414 - src.common.layers - INFO - Train: 0.9916666666666667, test: 0.9727\n",
      "2018-11-04 22:11:23,917 - src.common.layers - INFO - Train: 0.99215, test: 0.9744\n",
      "2018-11-04 22:11:25,349 - src.common.layers - INFO - Train: 0.9925, test: 0.9734\n",
      "2018-11-04 22:11:26,777 - src.common.layers - INFO - Train: 0.9930666666666667, test: 0.9747\n",
      "2018-11-04 22:11:28,229 - src.common.layers - INFO - Train: 0.9934, test: 0.9742\n",
      "2018-11-04 22:11:29,748 - src.common.layers - INFO - Train: 0.9935833333333334, test: 0.9743\n",
      "2018-11-04 22:11:31,192 - src.common.layers - INFO - Train: 0.99235, test: 0.9741\n",
      "2018-11-04 22:11:32,627 - src.common.layers - INFO - Train: 0.99445, test: 0.9742\n",
      "2018-11-04 22:11:34,105 - src.common.layers - INFO - Train: 0.9947666666666667, test: 0.9749\n",
      "2018-11-04 22:11:35,674 - src.common.layers - INFO - Train: 0.9947666666666667, test: 0.9751\n",
      "2018-11-04 22:11:37,099 - src.common.layers - INFO - Train: 0.9936333333333334, test: 0.974\n",
      "2018-11-04 22:11:38,525 - src.common.layers - INFO - Train: 0.99525, test: 0.9745\n",
      "2018-11-04 22:11:39,936 - src.common.layers - INFO - Train: 0.9953666666666666, test: 0.9748\n",
      "2018-11-04 22:11:41,458 - src.common.layers - INFO - Train: 0.9941666666666666, test: 0.973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.8 s, sys: 4.49 s, total: 46.3 s\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(iters_num):\n",
    "        batch_mask = np.random.choice(train_size, batch_size)\n",
    "        x_batch = x_train[batch_mask]\n",
    "        t_batch = t_train[batch_mask]\n",
    "        \n",
    "        # gradients by back propagation\n",
    "        grad = network.gradient(x_batch, t_batch)\n",
    "        \n",
    "        # update\n",
    "        for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "                network.params[key] -= learning_rate * grad[key]\n",
    "        \n",
    "        loss = network.loss(x_batch, t_batch)\n",
    "        train_loss_list.append(loss)\n",
    "        \n",
    "        if i % iter_per_epoch == 0:\n",
    "                train_acc = network.accuracy(x_train, t_train)\n",
    "                test_acc = network.accuracy(x_test, t_test)\n",
    "                train_acc_list.append(train_acc)\n",
    "                test_acc_list.append(test_acc)\n",
    "                logger.info(f\"Train: {train_acc}, test: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x110166a90>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label = 'train_acc')\n",
    "plt.plot(x, test_acc_list, label = 'test_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
